{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing the 04 notebooks\n",
    "\n",
    "These notebooks contain different models and feature engineering methods. The models are run quickly to get a rough idea of the performance of each model.\n",
    "\n",
    "The models include NN based models and traditional ML based models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion of the models\n",
    "\n",
    "- NN based models (CNN RNN)\n",
    "  - Model overfits to training data in any situation and any model complexity\n",
    "  - Generated features are insufficient for NN models\n",
    "- Traditional ML\n",
    "  - Multi-Ticker vs. Single-Ticker\n",
    "    - Single models performed better on recall but not on precision\n",
    "\t- Considering that percision is more important and a general model for multi-tickers is preferred, will focus on multi-ticker model\n",
    "  - 1D data vs extended data\n",
    "    - Extended data helps precision in both train and value.\n",
    "\t- Isolation Forest performed better than expected.\n",
    "\t- SVC had extremely good accuracy (but poor recall).\n",
    "\t- LightGBM may need extensive tuning to perform better.\n",
    "\t- Binary classes work better\n",
    "\t- Models to consider (binary classifier if not specified)\n",
    "\t  - Isolation Forest + raw data\n",
    "\t  - SVC + norm data \n",
    "\t  - lightgbm (multi-classifier + raw data performs better)\n",
    "\t  - Anomaly detection models performed quite well, consider rough tuning more similar models.\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
