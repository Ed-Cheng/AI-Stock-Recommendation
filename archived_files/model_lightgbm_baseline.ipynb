{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "\n",
    "from scripts.preparation import download_data, preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ticker(df_row):\n",
    "    capital = 0\n",
    "    for letter in df_row:\n",
    "        if letter.isupper():\n",
    "            capital += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    answer = df_row[:capital-1]\n",
    "    \n",
    "    special_case = {\"NVDANVIDI\": \"NVDA\",\n",
    "                    \"QCOMQUALCOM\": \"QCOM\",\n",
    "                    \"RTXRT\": \"RTX\",\n",
    "                    \"CVSCV\": \"CVS\",\n",
    "                    \"IACIA\": \"IAC\",\n",
    "                    \"GGEVG\": \"GEV\",\n",
    "                    \"EOGEO\": \"EOG\",\n",
    "                    \"NXPINX\": \"NXPI\",\n",
    "                    \"JPMJ\": \"JPM\"\n",
    "                    }\n",
    "    if answer in special_case.keys():\n",
    "        return special_case[answer]\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CMCSA']\n"
     ]
    }
   ],
   "source": [
    "top100 = pd.read_html(\"https://www.tradingview.com/markets/stocks-usa/market-movers-active/\")\n",
    "ticker_list = top100[0][\"Symbol\"].apply(extract_ticker)\n",
    "print([i for i in ticker_list if len(i) > 4])\n",
    "\n",
    "ticker_object = download_data(ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# russell_table = pd.read_html(\"https://en.wikipedia.org/wiki/Russell_1000_Index\")\n",
    "# ticker_list = list(russell_table[2][\"Ticker\"])\n",
    "\n",
    "# ticker_object = download_data(ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "data_set = pd.DataFrame()\n",
    "counter = 0\n",
    "\n",
    "for ticker in ticker_list:\n",
    "    if \".\" in ticker:\n",
    "        continue\n",
    "    \n",
    "    stock_data = ticker_object.tickers[ticker].history(period=\"500d\")\n",
    "    stock_data, train_features, target = preprocess(stock_data)\n",
    "    stock_data[\"ticker\"] = ticker\n",
    "\n",
    "    # print(stock_data[\"volatility20\"].tail(50).mean())\n",
    "\n",
    "    # if (stock_data[\"volatility5\"].tail(50).mean()) < 0.001:\n",
    "    #     continue\n",
    "\n",
    "    data_set = pd.concat([data_set, stock_data[train_features + target + [\"ticker\"]]])\n",
    "\n",
    "    counter += 1\n",
    "    # if counter > 50:\n",
    "    #     break\n",
    "    if counter % 10 == 0:\n",
    "        print(counter)\n",
    "\n",
    "data_set[target] = data_set[target].astype(int)\n",
    "data_set = data_set.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "short_target\n",
       "1    37094\n",
       "2     2988\n",
       "0     2480\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set[\"short_target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "long_target\n",
       "1    18791\n",
       "2    13337\n",
       "0    10434\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set[\"long_target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_eval(y_true, y_pred, label):\n",
    "    instance = np.where(y_true == label)[0]\n",
    "    predict = np.where(y_pred == label)[0]\n",
    "    correct = np.intersect1d(instance, predict) \n",
    "\n",
    "    print(f\"----- For Class {label} -----\")\n",
    "    # Recall: how many instances is detected\n",
    "    print(f\"Recall: {len(correct) / (len(instance))}\")\n",
    "\n",
    "    # Precision: how many of the predicted are correct\n",
    "    print(f\"Precision: {len(correct) / (len(predict))}\")\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # \"device\": \"gpu\",\n",
    "    # \"n_estimators\": 3000,\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": 3,\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"num_leaves\": 128,\n",
    "    \"learning_rate\": 0.005,\n",
    "    # \"feature_fraction\": 0.8,\n",
    "    # \"bagging_fraction\": 0.8,\n",
    "    # \"bagging_freq\": 5,\n",
    "    \"verbose\": -1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoder = LabelEncoder()\n",
    "# data_set[\"ticker\"] = label_encoder.fit_transform(data_set[\"ticker\"])\n",
    "# encoding_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "# target_type = \"short_target\"\n",
    "target_type = \"long_target\"\n",
    "\n",
    "X = data_set[train_features]\n",
    "y = data_set[target_type]\n",
    "\n",
    "train_size = int(0.8 * len(data_set))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_type == \"short_target\":\n",
    "    params.update(\n",
    "        {\n",
    "            \"class_weight\": {\n",
    "                0: 10,\n",
    "                1: 1,\n",
    "                2: 10,\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "elif target_type == \"long_target\":\n",
    "    params.update(\n",
    "        {\n",
    "            \"class_weight\": {\n",
    "                0: 2,\n",
    "                1: 1,\n",
    "                2: 2,\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(**params)\n",
    "lgb_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    callbacks=[lgb.callback.early_stopping(stopping_rounds=500),\n",
    "            #    lgb.callback.log_evaluation(period=100)\n",
    "               ],\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strict_pred(data):\n",
    "    data = np.where(data > 0.45, 1, 0)\n",
    "    data = np.argmax(data, axis=1)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgb_model.predict(X_test)\n",
    "y_pred = strict_pred(y_pred)\n",
    "multiclass_eval(y_test, y_pred, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- For Class 2 -----\n",
      "Recall: 0.0996\n",
      "Precision: 0.36403508771929827\n"
     ]
    }
   ],
   "source": [
    "multiclass_eval(y_test, y_pred, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36549683, 0.24179164, 0.39271153],\n",
       "       [0.3138228 , 0.28135975, 0.40481745],\n",
       "       [0.32127913, 0.26463572, 0.41408515],\n",
       "       [0.31007175, 0.3062086 , 0.38371965],\n",
       "       [0.32398965, 0.32312197, 0.35288838],\n",
       "       [0.32574828, 0.29687532, 0.37737639],\n",
       "       [0.28007689, 0.33747685, 0.38244626],\n",
       "       [0.31320268, 0.27407147, 0.41272585],\n",
       "       [0.31391529, 0.29272603, 0.39335867],\n",
       "       [0.27278309, 0.2949751 , 0.43224181],\n",
       "       [0.30686561, 0.35411683, 0.33901756],\n",
       "       [0.27517148, 0.2709992 , 0.45382932],\n",
       "       [0.270396  , 0.21766226, 0.51194174],\n",
       "       [0.31524485, 0.28340164, 0.40135351],\n",
       "       [0.31431292, 0.19772681, 0.48796028],\n",
       "       [0.30788626, 0.26441112, 0.42770262],\n",
       "       [0.33005261, 0.30331235, 0.36663504],\n",
       "       [0.32001527, 0.32362407, 0.35636067],\n",
       "       [0.30788759, 0.31089237, 0.38122004],\n",
       "       [0.3073687 , 0.21084566, 0.48178563]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model.predict(X_test)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- For Class 0 -----\n",
      "Recall: 0.19667590027700832\n",
      "Precision: 0.29338842975206614\n",
      "----- For Class 1 -----\n",
      "Recall: 0.16017110266159695\n",
      "Precision: 0.6217712177121771\n",
      "----- For Class 2 -----\n",
      "Recall: 0.754\n",
      "Precision: 0.303103392828429\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgb_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "for i in range(0, 3):\n",
    "    multiclass_eval(y_test, y_pred, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow\n",
    "https://www.tensorflow.org/tutorials/structured_data/time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.metrics import Recall\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "# target_type = \"short_target\"\n",
    "target_type = \"long_target\"\n",
    "#\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(data_set[train_features])\n",
    "y = data_set[target_type].values\n",
    "\n",
    "if target_type == \"short_target\":\n",
    "    class_weight = {0: 10, 1: 1, 2: 10}\n",
    "elif target_type == \"long_target\":\n",
    "    class_weight = {0: 2, 1: 1, 2: 2}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42562, 36)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for CNN\n",
    "# X = X.reshape(1, X.shape[1], (X.shape[0]))\n",
    "\n",
    "# Split data into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(data_set))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# X_train = X_train.reshape(1, X_train.shape[1], (X_train.shape[0]))\n",
    "# X_test = X_test.reshape(1, X_test.shape[1], (X_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train x  (34049, 36)\n",
      "train label  (34049,)\n",
      "test x  (8513, 36)\n",
      "test label  (8513,)\n"
     ]
    }
   ],
   "source": [
    "print(\"train x \", X_train.shape)\n",
    "print(\"train label \", y_train.shape)\n",
    "print(\"test x \", X_test.shape)\n",
    "print(\"test label \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edton\\miniconda3\\envs\\trading\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation=\"relu\", input_shape=(X_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation=\"relu\"))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation=\"relu\"))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(3, activation=\"softmax\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1065/1065\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.3193 - loss: 1.7053 - val_accuracy: 0.2937 - val_loss: 1.1351\n",
      "Epoch 2/10\n",
      "\u001b[1m1065/1065\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3217 - loss: 1.6971 - val_accuracy: 0.3242 - val_loss: 1.1118\n",
      "Epoch 3/10\n",
      "\u001b[1m1065/1065\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3495 - loss: 1.6813 - val_accuracy: 0.3354 - val_loss: 1.1085\n",
      "Epoch 4/10\n",
      "\u001b[1m1065/1065\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3650 - loss: 1.6784 - val_accuracy: 0.3957 - val_loss: 1.0867\n",
      "Epoch 5/10\n",
      "\u001b[1m1065/1065\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3758 - loss: 1.6717 - val_accuracy: 0.3387 - val_loss: 1.1289\n",
      "Epoch 6/10\n",
      "\u001b[1m1065/1065\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3890 - loss: 1.6651 - val_accuracy: 0.4350 - val_loss: 1.0777\n",
      "Epoch 7/10\n",
      "\u001b[1m1065/1065\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3891 - loss: 1.6655 - val_accuracy: 0.4641 - val_loss: 1.0589\n",
      "Epoch 8/10\n",
      "\u001b[1m1065/1065\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4111 - loss: 1.6550 - val_accuracy: 0.3786 - val_loss: 1.1044\n",
      "Epoch 9/10\n",
      "\u001b[1m1065/1065\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4100 - loss: 1.6534 - val_accuracy: 0.4062 - val_loss: 1.0992\n",
      "Epoch 10/10\n",
      "\u001b[1m1065/1065\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4126 - loss: 1.6490 - val_accuracy: 0.3719 - val_loss: 1.1101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c5095e7f70>"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=10, \n",
    "          batch_size=32, \n",
    "          validation_data=(X_test, y_test),\n",
    "          class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "----- For Class 2 -----\n",
      "Recall: 0.166\n",
      "Precision: 0.35837651122625214\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = strict_pred(y_pred)\n",
    "multiclass_eval(y_test, y_pred, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/267\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 19ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "----- For Class 2 -----\n",
      "Recall: 0.3772\n",
      "Precision: 0.3036059240180296\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "multiclass_eval(y_test, y_pred, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
